# This file configures Charmcraft.
# See https://juju.is/docs/sdk/charmcraft-config for guidance.

name: opentelemetry-collector-k8s
type: charm
summary: Vendor-agnostic way to receive, process and export telemetry data.
description: |
  The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive,
  process and export telemetry data. In addition, it removes the need to run, operate and
  maintain multiple agents/collectors in order to support open-source telemetry data formats
  (e.g. Jaeger, Prometheus, etc.) to multiple open-source or commercial back-ends.

links:
  # documentation: https://discourse.charmhub.io/
  website: https://charmhub.io/opentelemetry-collector-k8s
  source: https://github.com/canonical/opentelemetry-collector-k8s-operator
  issues: https://github.com/canonical/opentelemetry-collector-k8s-operator/issues

assumes:
  - k8s-api
  - juju >= 3.6

platforms:
  ubuntu@24.04:amd64:
  ubuntu@24.04:arm64:

parts:
  charm:
    source: .
    plugin: uv
    build-packages: [git]
    build-snaps: [astral-uv]
    override-build: |
      craftctl default
      git describe --always > $CRAFT_PART_INSTALL/version
  cos-tool:
    plugin: dump
    source: https://github.com/canonical/cos-tool/releases/latest/download/cos-tool-${CRAFT_ARCH_BUILD_FOR}
    source-type: file
    permissions:
      - path: cos-tool-${CRAFT_ARCH_BUILD_FOR}
        mode: "755"

containers:
  otelcol:
    resource: opentelemetry-collector-image
    mounts:
      - storage: persisted
        location: /otelcol

storage:
  persisted:
    type: filesystem
    description: Mount point in which Otelcol will persist data

resources:
  opentelemetry-collector-image:
    type: oci-image
    description: OCI image for opentelemetry-collector
    upstream-source: ubuntu/opentelemetry-collector@sha256:d9efc1370de1c530da69a1f182180769f4aef439c43751ddf2876f4e0e80e7a5  # renovate: oci-image tag: 0.138-24.04

provides:
  grafana-dashboards-provider:
    interface: grafana_dashboard
    description: |
      Send own and aggregated dashboards to grafana.
  receive-loki-logs:
    interface: loki_push_api
    optional: true
    description: To receive logs by allowing Promtail instances to specify otelcol as their Loki address.
  receive-traces:
    interface: tracing
    optional: true
    description: Receive traces from other charms.
  # TODO https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/37277
  # receive-remote-write:
  #   interface: prometheus_remote_write
  provide-cmr-mesh:
    interface: cross_model_mesh
    description: |
      Access a cross-model application from otel via the service mesh.
      This relation provides additional data required by the service mesh to enforce cross-model authorization policies
  receive-profiles:
    interface: profiling
    optional: true
    description: Receive profiles from other charms.

requires:
  send-profiles:
    interface: profiling
    optional: true
    description: Forward profiles to other charms.
  grafana-dashboards-consumer:
    interface: grafana_dashboard
    description: |
      Collect dashboards to be forwarded to grafana.
  metrics-endpoint:
    interface: prometheus_scrape
    optional: true
    description: To scrape other charms' metrics endpoints.
  send-remote-write:
    interface: prometheus_remote_write
    optional: true
    description: To forward collected metrics to a Prometheus backend.
  send-loki-logs:
    interface: loki_push_api
    optional: true
    description: To forward collected logs to a Loki backend.
  receive-ca-cert:
    interface: certificate_transfer
    optional: true
    description: |
      For otelcol to create a trusted (TLS) connection with servers
      it scrapes, pushes to, etc., it needs to trust the CA that signed
      the server it talks to. CA certs forwarded over this relation are
      installed in the root CA store.
  cloud-config:
    interface: grafana_cloud_config
    optional: true
    limit: 1
    description: Forward telemetry to another Observability stack (Grafana Cloud, COS, etc.).
  receive-server-cert:
    interface: tls-certificates
    optional: true
    limit: 1
    description: |
      Obtain a certificate from a CA.
      The charm sends a CSR over this relation and receives a signed certificate back.
      That is the cert that would be presented to incoming TLS connections.
  # TODO: remove limit once https://github.com/canonical/tempo-coordinator-k8s-operator/issues/168 is resolved
  send-traces:
    interface: tracing
    limit: 1
    optional: true
    description: Send traces to a charmed Tempo instance.
  service-mesh:
    limit: 1
    interface: service_mesh
    description: |
      Subscribe this charm into a service mesh to enforce authorization policies.
  require-cmr-mesh:
    interface: cross_model_mesh
    description: |
      Allow a cross-model application access to otel via the service mesh.
      This relation provides additional data required by the service mesh to enforce cross-model authorization policies.
  send-charm-traces:
    interface: tracing
    limit: 1
    optional: true
    description: Send charm traces to a charmed Tempo instance.

config:
  options:
    processors:
      type: string
      description: |
        A global opentelemetry-collector "processors" config in YAML format, without the
        "processors:" top-level key. For example, to represent a "processors" section
        such as:

            processors:
              batch:
              memory_limiter:
                limit_mib: 4000

        you could use `juju config otelcol processors=@processors.yaml`, with:

            # processors.yaml
            batch:
            memory_limiter:
              limit_mib: 4000

        The provided processors section will be applied to all relevant pipelines.

        Reference: https://opentelemetry.io/docs/collector/configuration/#processors
    forward_alert_rules:
      description: >
        Toggle forwarding of alert rules.
      type: boolean
      default: true
    tls_insecure_skip_verify:
      description: |
        Flag to skip the validation of certificates from servers we connect to with TLS.
        If "true", self-signed certs can be used seamlessly; this setting will be applied
        to all the otelcol exporter configurations and any receivers which actively make
        requests to servers, e.g. the prometheus receiver scraping metrics endpoints.
      type: boolean
      default: false
    # Tracing config options
    always_enable_zipkin:
      description: >
        Force-enable the receiver for the 'zipkin' protocol in OpenTelemetry Collector,
        even if there is no integration currently requesting it.
      type: boolean
      default: false
    always_enable_jaeger_grpc:
      description: >
        Force-enable the receiver for the 'jaeger_grpc' protocol in OpenTelemetry Collector,
        even if there is no integration currently requesting it.
      type: boolean
      default: false
    always_enable_jaeger_thrift_http:
      description: >
        Force-enable the receiver for the 'jaeger_thrift_http' protocol in OpenTelemetry Collector,
        even if there is no integration currently requesting it.
      type: boolean
      default: false
    max_elapsed_time_min:
      type: int
      default: 5
      description: |
        Maximum time in minutes to wait for the storage backend. After this time, data loss will occur.
    queue_size:
      type: int
      default: 1000
      description: |
        Maximum number of incoming batches of metrics, logs, traces the queue can accept.
        Ref: https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md#configuration
    tracing_sampling_rate_charm:
      description: >
        This property defines the percentage of charm traces that are sent to the tracing backend.
        Setting it to 100 would mean all charm traces are kept, setting to 0 means charm traces
        aren't sent to the tracing backend at all. Anything outside of 0-100 range will be clamped
        to this range by OpenTelemetry Collector.
      type: float
      default: 100.0
    tracing_sampling_rate_workload:
      description: >
        This property defines the percentage of workload traces that are sent to the tracing backend.
        Setting it to 100 would mean all workload traces are kept, setting to 0 means workload traces
        aren't sent to the tracing backend at all. Anything outside of 0-100 range will be clamped
        to this range by OpenTelemetry Collector.
      type: float
      default: 1.0
    tracing_sampling_rate_error:
      description: >
        This property defines the percentage of error traces (from all sources) that are sent to the tracing backend.
        Setting it to 100 would mean all error traces are kept, setting to 0 means error traces
        aren't sent to the tracing backend at all. Anything outside of 0-100 range will be clamped
        to this range by OpenTelemetry Collector.
      type: float
      default: 100.0
    extra_alert_labels:
      description: >
        Comma separated key-value pairs of labels to be added to all alerts.
        This could be useful for differentiating between staging and production environments.
      type: string
    global_scrape_timeout:
      description: >
        How long to wait before timing out a scrape from a target.
        Supported units: y, w, d, h, m, s.
      type: string
      default: "10s"
    global_scrape_interval:
      description: >
        How frequently should instances be scraped.
        Supported units: y, w, d, h, m, s.
      type: string
      default: "1m"
    cpu:
      description: |
        K8s cpu resource limit, e.g. "1" or "500m". Default is unset (no limit). This value is used
        for the "limits" portion of the resource requirements (the "requests" portion is
        automatically deduced from it).
        Note that changing this config option will churn the pod.
        See https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
      type: string
    memory:
      description: |
        K8s memory resource limit, e.g. "1Gi". Default is unset (no limit). This value is used
        for the "limits" portion of the resource requirements (the "requests" portion is
        automatically deduced from it).
        Note that changing this config option will churn the pod.
        See https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
      type: string

actions:
  reconcile:
    description: >
      Regenerate the world state from scratch. This includes the configuration file,
      but also relation data set by the charm.
